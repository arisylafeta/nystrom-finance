{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_positive_semi_definite(matrix):\n",
    "    \"\"\"\n",
    "        Checks if a matrix is positive semi-definite.\n",
    "    \"\"\"\n",
    "    eigenvalues = np.linalg.eigvalsh(matrix)\n",
    "    return np.all(eigenvalues >= -1e-10)  # Allowing for numerical precision issues\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "               # HELPER FUNCTIONS FOR THE NOTEBOOK\n",
    "####################################################################################################\n",
    "def frobenius_norm_difference(A, B):\n",
    "    \"\"\"\n",
    "        Calculates the Frobenius norm of the difference between two matrices.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(A - B, 'fro') / np.linalg.norm(A, 'fro')\n",
    "\n",
    "def sample_covariance_estimator(X):\n",
    "    \"\"\"\n",
    "        Estimates the covariance matrix of a data matrix.\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    covariance_matrix = np.dot(X, X.T) / n\n",
    "    \n",
    "    return covariance_matrix\n",
    "\n",
    "def generate_sample_data(n_features, n_samples, rank):\n",
    "    \"\"\"\n",
    "    Generates a sample data matrix with a specified low rank.\n",
    "    \"\"\"\n",
    "    rank = min(rank, n_features, n_samples)\n",
    "    A = np.random.randn(n_features, rank) @ np.random.randn(rank, n_samples)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_eigenvalues(eigvals_sample, eigvals_nystrom, k):\n",
    "    top_eigvals_sample = eigvals_sample[:k]\n",
    "    top_eigvals_nystrom = eigvals_nystrom[:k]\n",
    "    relative_error = np.linalg.norm(top_eigvals_sample - top_eigvals_nystrom) / np.linalg.norm(top_eigvals_sample)\n",
    "    return relative_error\n",
    "\n",
    "def compare_eigenvectors(eigvecs_sample, eigvecs_nystrom, k):\n",
    "    top_eigvecs_sample = eigvecs_sample[:, :k]\n",
    "    top_eigvecs_nystrom = eigvecs_nystrom[:, :k]\n",
    "    frobenius_norm = np.linalg.norm(top_eigvecs_sample - top_eigvecs_nystrom, 'fro') / np.linalg.norm(top_eigvecs_sample, 'fro')\n",
    "    return frobenius_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nystorm Covariance Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nystrom_covariance_estimator(X, num_landmarks):\n",
    "    \"\"\"\n",
    "        Estimates the covariance matrix of a data matrix using the Nyström method.\n",
    "    \"\"\"\n",
    "    p, n = X.shape      # p: number of features, n: number of samples\n",
    "\n",
    "    # Step 1: Select landmark points (randomly select num_landmarks columns)\n",
    "    indices = np.random.choice(p, num_landmarks, replace=False)\n",
    "    Y = X[indices, :]      # Y.shape = (num_landmarks, n)\n",
    "\n",
    "    # Step 2: Compute the orthogonal projection matrix P using the pseudoinverse\n",
    "    YYT = np.dot(Y, Y.T) \n",
    "    YYT_pinv = np.linalg.pinv(YYT)\n",
    "    P = np.dot(Y.T, np.dot(YYT_pinv, Y))    # P.shape = (n, n)\n",
    "\n",
    "    # Step 3: Project data onto the subspace spanned by the landmark points\n",
    "    X_proj = np.dot(X, P)\n",
    "    \n",
    "    # Step 4: Construct the Nyström covariance estimator\n",
    "    Sigma_hat = np.dot(X_proj, X.T) / n    # Sigma_hat.shape = (p, p)\n",
    "    \n",
    "    return Sigma_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bias of Nystorm Covariance Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nystorm_estimator_bias(Sigma, Sigma_hat, I, J, n, k):\n",
    "    \"\"\"\n",
    "        Computes the bias of the Nyström covariance estimator.\n",
    "    \"\"\"\n",
    "    Sigma_I = Sigma[np.ix_(I, I)]\n",
    "    Sigma_J = Sigma[np.ix_(J, J)]\n",
    "    Sigma_IJ = Sigma[np.ix_(I, J)]\n",
    "    Schur_complement = Sigma_J - Sigma_IJ.T @ np.linalg.inv(Sigma_I) @ Sigma_IJ\n",
    "    \n",
    "    B_J = ((n - k) / n) * Schur_complement\n",
    "    B = np.zeros_like(Sigma)\n",
    "    B[np.ix_(J, J)] = B_J\n",
    "    \n",
    "    return B, Schur_complement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE of Nystorm Covariance Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nystorm_estimator_mse(Sigma, Sigma_hat, n, k, I):\n",
    "    \"\"\"\n",
    "    Computes the mean square error (MSE) of the Nyström covariance estimator.\n",
    "    \"\"\"\n",
    "\n",
    "    Sigma_I = Sigma_hat[np.ix_(I, I)]\n",
    "    # MSE of the sample covariance estimator of the Schur complement\n",
    "    MSE_Sigma_I_Schur = (1 / (n - k)) * (np.trace(Sigma_I @ Sigma_I) + np.trace(Sigma_I) ** 2)\n",
    "    # MSE of the sample covariance estimator\n",
    "    MSE_Sigma = (1 / n) * (np.trace(Sigma @ Sigma) + np.trace(Sigma) ** 2)\n",
    "    # Compute the MSE of the Nyström covariance estimator\n",
    "    MSE = MSE_Sigma + (((n - k)** 2) / n ** 2) * (np.linalg.norm(Sigma_I, 'fro') - MSE_Sigma_I_Schur)\n",
    "    \n",
    "    return MSE, MSE_Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test of Nystorm Covariance Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm difference between the sample covariance matrix and the Nyström estimator: 0.00%\n",
      "Is the Nyström estimator positive semi-definite? True\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "p, n, rank = 100, 50, 10  # Number of features, number of samples, rank of the data matrix\n",
    "X = generate_sample_data(p, n, rank)\n",
    "\n",
    "k = 10  # Number of landmark points (tests with different values of this parameter can be found below)\n",
    "Sigma = sample_covariance_estimator(X)\n",
    "Sigma_hat = nystrom_covariance_estimator(X, k)\n",
    "\n",
    "# Compute bias\n",
    "I = np.random.choice(p, k, replace=False)\n",
    "J = np.setdiff1d(np.arange(p), I)\n",
    "#bias, schur = nystorm_estimator_bias(Sigma, Sigma_hat, I, J, n, k)\n",
    "#expected_value = \n",
    "\n",
    "# Compute MSE\n",
    "#mse, mse_sample = nystorm_estimator_mse(Sigma, Sigma_hat, n, k, I)\n",
    "\n",
    "print(\"Frobenius norm difference between the sample covariance matrix and the Nyström estimator: {:.2f}%\".format(frobenius_norm_difference(Sigma, Sigma_hat)))\n",
    "print(\"Is the Nyström estimator positive semi-definite? {}\".format(is_positive_semi_definite(Sigma_hat)))\n",
    "print(Sigma_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nystorm SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm Difference for Relation (1) 6.094143089049153e-14\n",
      "Frobenius Norm Difference for Relation (2) 6.388136660264183e-14\n",
      "Frobenius Norm Difference for Relation (3) 6.865837747188016e-14\n",
      "Frobenius Norm Difference for Relation (4) 6.323765702091671e-13\n",
      "Relative error of the eigenvalues between Nystrom and PCA Nystrom: 0.00%\n",
      "Relative error of eigenvectors between Nystrom and PCA Nystrom: 1.43\n",
      "Frobenius norm difference between the sample covariance matrix and the Nyström estimator: 0.00%\n",
      "Frobenius norm difference between the Nystorm Covariance estimator and the Nyström PCA estimator: 135.25%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "####################################################################################################\n",
    "               # HELPER FUNCTIONS FOR THE NOTEBOOK\n",
    "####################################################################################################\n",
    "\n",
    "def frobenius_norm_difference(A, B):\n",
    "    \"\"\"\n",
    "        Calculates the Frobenius norm of the difference between two matrices.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(A - B, 'fro') / np.linalg.norm(A, 'fro') * 100\n",
    "\n",
    "def sample_covariance_estimator(X):\n",
    "    \"\"\"\n",
    "        Estimates the sample covariance matrix of a data matrix.\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    covariance_matrix = np.dot(X, X.T) / n\n",
    "    \n",
    "    return covariance_matrix\n",
    "\n",
    "def generate_low_rank_data(n_features, n_samples, rank):\n",
    "    \"\"\"\n",
    "    Generates a low rank data matrix.\n",
    "    \"\"\"\n",
    "    rank = min(rank, n_features, n_samples)\n",
    "    A = np.random.randn(n_features, rank) @ np.random.randn(rank, n_samples)\n",
    "    \n",
    "    return A\n",
    "\n",
    "####################################################################################################\n",
    "                # NYSTROM COVARIANCE ESTIMATOR\n",
    "####################################################################################################\n",
    "def nystrom_covariance_estimator(X, num_landmarks):\n",
    "    \"\"\"\n",
    "        Estimates the covariance matrix of a data matrix using the Nyström method.\n",
    "    \"\"\"\n",
    "    p, n = X.shape      # p: number of features, n: number of samples\n",
    "\n",
    "    # Step 1: Select landmark points (randomly select num_landmarks columns)\n",
    "    indices = np.random.choice(p, num_landmarks, replace=False)\n",
    "    Y = X[indices, :]      # Y.shape = (num_landmarks, n)\n",
    "\n",
    "    # Step 2: Compute the orthogonal projection matrix P using the pseudoinverse\n",
    "    YYT = np.dot(Y, Y.T) \n",
    "    YYT_pinv = np.linalg.pinv(YYT)\n",
    "    P = np.dot(Y.T, np.dot(YYT_pinv, Y))    # P.shape = (n, n)\n",
    "\n",
    "    # Step 3: Project data onto the subspace spanned by the landmark points\n",
    "    X_proj = np.dot(X, P)\n",
    "    \n",
    "    # Step 4: Construct the Nyström covariance estimator\n",
    "    Sigma_hat = np.dot(X_proj, X.T) / n    # Sigma_hat.shape = (p, p)\n",
    "    \n",
    "    return Sigma_hat\n",
    "\n",
    "####################################################################################################\n",
    "                # NYSTROM PRINCIPAL COMPONENT ANALYSIS \n",
    "####################################################################################################\n",
    "def nystrom_pca(X, num_landmarks, k):\n",
    "    \"\"\"\n",
    "        Estimates the principal components of a data matrix using the Nyström method.\n",
    "    \"\"\"\n",
    "    p, n = X.shape  # p: number of features, n: number of samples\n",
    "\n",
    "    # Step 1: Select landmark points (randomly select num_landmarks columns)\n",
    "    indices_I = np.random.choice(p, num_landmarks, replace=False)\n",
    "    Y = X[indices_I, :]  # X_I.shape = (num_landmarks, n)\n",
    "\n",
    "    # Step 2: Define J and X_J\n",
    "    indices_J = np.setdiff1d(np.arange(p), indices_I)\n",
    "    Z = X[indices_J, :]  # X_J.shape = (p - num_landmarks, n)\n",
    "\n",
    "    # Step 3: Compute Thin SVD of X_I\n",
    "    U_Y, D_Y, V_Y_T = np.linalg.svd(Y, full_matrices=False)\n",
    "    # Step 4: Construct W_I and W_J\n",
    "    W_Y = (1 / np.sqrt(n)) * np.dot(U_Y, np.diag(D_Y))\n",
    "    W_Z = (1 / np.sqrt(n)) * np.dot(Z, V_Y_T.T)\n",
    "\n",
    "    # Step 5: Compute W\n",
    "    W = np.vstack([W_Y, W_Z]) # I suspect the error is here\n",
    "\n",
    "    # Step 6: Perform thin SVD on W\n",
    "    U, Lambda, V_T = np.linalg.svd(W, full_matrices=False)\n",
    "\n",
    "    # Side step: Compute the projection matrix P\n",
    "    YYT = np.dot(Y, Y.T) \n",
    "    YYT_pinv = np.linalg.pinv(YYT)\n",
    "    P = np.dot(Y.T, np.dot(YYT_pinv, Y)) \n",
    "\n",
    "\n",
    "    Sigma_Nystrom = 1/n * (X @ P @ X.T)\n",
    "    # Eigenvalues and eigenvectors\n",
    "    eigenvalues = Lambda**2\n",
    "    eigenvectors = U\n",
    "\n",
    "    print(\"Frobenius Norm Difference for Relation (1)\", frobenius_norm_difference(Y @ Y.T, U_Y @ np.diag(D_Y) @ np.diag(D_Y) @ U_Y.T))\n",
    "    print(\"Frobenius Norm Difference for Relation (2)\", frobenius_norm_difference(Y @ Z.T, U_Y @ np.diag(D_Y) @ V_Y_T @ Z.T))\n",
    "    print(\"Frobenius Norm Difference for Relation (3)\", frobenius_norm_difference(Z @ Y.T, Z @ V_Y_T.T @ np.diag(D_Y) @ U_Y.T))\n",
    "    print(\"Frobenius Norm Difference for Relation (4)\", frobenius_norm_difference(P, V_Y_T.T @ V_Y_T))\n",
    "    # Covariance matrix estimator, should be equal to Nyström covariance estimator\n",
    "    Sigma_hat = np.dot(W, W.T)\n",
    "\n",
    "    return Sigma_hat, eigenvalues[:k], eigenvectors[:, :k]\n",
    "\n",
    "####################################################################################################\n",
    "                # EXAMPLE USAGE\n",
    "####################################################################################################\n",
    "\n",
    "p, n, rank = 100, 50, 10  # Number of features, number of samples, rank of the data matrix\n",
    "X = generate_low_rank_data(p, n, rank)  # Generate a low rank data matrix  \n",
    "\n",
    "# Sample covariance matrix\n",
    "Sigma_simple = sample_covariance_estimator(X)\n",
    "\n",
    "# Nyström covariance estimator\n",
    "num_landmarks = 10  # Number of landmark points\n",
    "Sigma_nystrom = nystrom_covariance_estimator(X, num_landmarks)\n",
    "\n",
    "# Nyström PCA\n",
    "k = 10  # Number of principal components\n",
    "Sigma_pca, eigvals_pca, eigvecs_pca = nystrom_pca(X, num_landmarks, k)\n",
    "\n",
    "# Assuming Sigma_nystrom is already defined and is a square symmetric matrix\n",
    "eigenvalues, eigenvectors = np.linalg.eig(Sigma_nystrom)\n",
    "\n",
    "# Sorting the eigenvalues and eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]  # Sort indices by eigenvalues in descending order\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Extract the 10 largest eigenvalues and corresponding eigenvectors\n",
    "top_10_eigenvalues = sorted_eigenvalues[:10]\n",
    "top_10_eigenvectors = sorted_eigenvectors[:, :10]\n",
    "\n",
    "# Compare the eigenvalues and eigenvectors\n",
    "relative_error_eigenvalues = compare_eigenvalues(eigvals_pca, top_10_eigenvalues, k)\n",
    "frobenius_norm_eigenvectors = compare_eigenvectors(eigvecs_pca, top_10_eigenvectors, k)\n",
    "\n",
    "print(\"Relative error of the eigenvalues between Nystrom and PCA Nystrom: {:.2f}%\".format(relative_error_eigenvalues * 100))\n",
    "print(\"Relative error of eigenvectors between Nystrom and PCA Nystrom: {:.2f}\".format(frobenius_norm_eigenvectors))\n",
    "\n",
    "# Compare the results\n",
    "print(\"Frobenius norm difference between the sample covariance matrix and the Nyström estimator: {:.2f}%\".format(frobenius_norm_difference(Sigma_simple, Sigma_nystrom)))\n",
    "print(\"Frobenius norm difference between the Nystorm Covariance estimator and the Nyström PCA estimator: {:.2f}%\".format(frobenius_norm_difference(Sigma_nystrom, Sigma_pca)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
