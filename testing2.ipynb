{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "def uniform_random_sample(X, num_landmarks, replace=False):\n",
    "    \"\"\"\n",
    "        Samples indices uniformly at random from a data matrix.\n",
    "    \"\"\"\n",
    "    p, n = X.shape \n",
    "    indices = np.random.choice(p, num_landmarks, replace=replace)\n",
    "    return indices\n",
    "\n",
    "def column_norm_sample(X, num_landmarks, replace=False):\n",
    "    \"\"\"Samples indices based on the column norms of a data matrix.\"\"\"\n",
    "    p, n = X.shape \n",
    "    \n",
    "    # Step 1: Compute the column norms\n",
    "    column_norms = np.linalg.norm(X, axis=1) \n",
    "\n",
    "    # Step 2: Compute the probabilities\n",
    "    probabilities = column_norms ** 2\n",
    "    probabilities /= np.sum(probabilities)\n",
    "\n",
    "    # Step 3: Sample indices based on the probabilities\n",
    "    indices = np.random.choice(p, num_landmarks, replace=replace, p=probabilities)\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "def generate_low_rank_data(n_features, n_samples, rank):\n",
    "    \"\"\"\n",
    "    Generates a low rank data matrix.\n",
    "    \"\"\"\n",
    "    rank = min(rank, n_features, n_samples)\n",
    "    A = np.random.randn(n_features, rank) @ np.random.randn(rank, n_samples)\n",
    "    \n",
    "    return A\n",
    "\n",
    "def compare_eigenvalues(eigvals_sample, eigvals_nystrom, k):\n",
    "    eigvals_sample = eigvals_sample[:k]\n",
    "    eigvals_nystrom = eigvals_nystrom[:k]\n",
    "    relative_error = np.linalg.norm(eigvals_sample - eigvals_nystrom) / np.linalg.norm(eigvals_sample)\n",
    "    return relative_error\n",
    "\n",
    "def compare_eigenvectors(eigvecs_sample, eigvecs_nystrom, k):\n",
    "    eigvecs_sample = eigvecs_sample[:, :k]\n",
    "    eigvecs_nystrom = eigvecs_nystrom[:, :k]\n",
    "    # Adjust signs\n",
    "    for i in range(eigvecs_sample.shape[1]):\n",
    "        if np.dot(eigvecs_sample[:, i], eigvecs_nystrom[:, i]) < 0:\n",
    "            eigvecs_nystrom[:, i] *= -1\n",
    "    \n",
    "    frobenius_norm = np.linalg.norm(eigvecs_sample - eigvecs_nystrom, 'fro') / np.linalg.norm(eigvecs_sample, 'fro')\n",
    "    return frobenius_norm\n",
    "\n",
    "def nystrom_pca(X, indices, num_landmarks):\n",
    "    \"\"\"\n",
    "        Estimates the principal components of a data matrix using the NystrÃ¶m method.\n",
    "    \"\"\"\n",
    "    p, n = X.shape\n",
    "    Y = X[indices, :]  # X_I.shape = (num_landmarks, n)\n",
    "\n",
    "    # Step 2: Define J and X_J\n",
    "    indices_J = np.setdiff1d(np.arange(p), indices)\n",
    "    Z = X[indices_J, :]  # X_J.shape = (p - num_landmarks, n)\n",
    "\n",
    "    # Step 3: Compute Thin SVD of X_I\n",
    "    U_Y, D_Y, V_Y_T = np.linalg.svd(Y, full_matrices=False)\n",
    "    # Step 4: Construct W_I and W_J\n",
    "    W_Y = (1 / np.sqrt(n)) * U_Y @ np.diag(D_Y)\n",
    "    W_Z = (1 / np.sqrt(n)) * Z @ V_Y_T.T\n",
    "\n",
    "    # Initialize W with the same shape as X\n",
    "    W = np.zeros((p, num_landmarks))\n",
    "    W[indices, :] = W_Y\n",
    "    W[indices_J, :] = W_Z\n",
    "\n",
    "    # Step 6: Perform thin SVD on W\n",
    "    U, Lambda, V_T = np.linalg.svd(W, full_matrices=False)\n",
    "\n",
    "    # Eigenvalues and eigenvectors\n",
    "    eigenvalues = Lambda**2\n",
    "    eigenvectors = U\n",
    "\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def sample_svd(X):\n",
    "    \"\"\"\n",
    "        Estimates the sample covariance matrix of a data matrix.\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    U_Y, D_Y, V_Y_T = np.linalg.svd(X, full_matrices=False)\n",
    "    eigenvalues = D_Y**2 / n\n",
    "    eigenvectors = U_Y\n",
    "\n",
    " \n",
    "    return eigenvalues, eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def recursive_rls_sample(X, num_landmarks=None, replace=False, accelerated_flag=False):\n",
    "    p, r = X.shape\n",
    "    \n",
    "    if num_landmarks is None:\n",
    "        s = int(np.ceil(np.sqrt(p)))\n",
    "    else:\n",
    "        s = num_landmarks\n",
    "    \n",
    "    kernel_func = lambda X, row_ind, col_ind: (X[row_ind, :] @ X[col_ind, :].T if len(col_ind) > 0 else np.sum(X[row_ind, :]**2, axis=1))\n",
    "    \n",
    "    if not accelerated_flag:\n",
    "        s_level = s\n",
    "    else:\n",
    "        s_level = int(np.ceil(np.sqrt((p * s + s**3) / (4 * p))))\n",
    "    \n",
    "    oversamp = np.log(s_level)\n",
    "    k = int(np.ceil(s_level / (4 * oversamp)))\n",
    "    n_levels = int(np.ceil(np.log(p / s_level) / np.log(2)))\n",
    "    \n",
    "    perm = np.random.permutation(p)\n",
    "    \n",
    "    l_size = [p]\n",
    "    for _ in range(n_levels):\n",
    "        l_size.append(int(np.ceil(l_size[-1] / 2)))\n",
    "    \n",
    "    samp = np.arange(l_size[-1])\n",
    "    r_ind = perm[samp]\n",
    "    weights = np.ones(len(r_ind))\n",
    "    \n",
    "    k_diag = kernel_func(X, np.arange(p), [])\n",
    "    \n",
    "    for l in range(n_levels, 0, -1):\n",
    "        r_ind_curr = perm[:l_size[l-1]]\n",
    "        KS = kernel_func(X, r_ind_curr, r_ind)\n",
    "        SKS = KS[samp, :]\n",
    "        SKSn = SKS.shape[0]\n",
    "        \n",
    "        if k >= SKSn:\n",
    "            lambda_ = 1e-6\n",
    "        else:\n",
    "            diag_sum = np.sum((SKS.diagonal() * weights**2))\n",
    "            SKS_weighted = SKS * weights[:, np.newaxis]\n",
    "            eigvals = eigsh(SKS_weighted @ SKS_weighted.T, k=k, which='LM', return_eigenvectors=False)\n",
    "            eig_sum = np.sum(np.abs(eigvals))\n",
    "            lambda_ = (diag_sum - eig_sum) / k\n",
    "        \n",
    "        if l != 1:\n",
    "            R = linalg.inv(SKS + np.diag(lambda_ * weights**(-2)))\n",
    "            levs = np.maximum(0, np.minimum(1, oversamp * (1/lambda_) * np.maximum(0, k_diag[r_ind_curr] - np.sum((KS @ R) * KS, axis=1))))\n",
    "            levs_sum = np.sum(levs)\n",
    "            if levs_sum == 0 or np.count_nonzero(levs) < s_level:\n",
    "                samp = np.random.choice(l_size[l-1], size=s_level, replace=False)\n",
    "            else:\n",
    "                samp = np.random.choice(l_size[l-1], size=s_level, replace=False, p=levs / levs_sum)\n",
    "            \n",
    "            weights = np.sqrt(1 / np.maximum(levs[samp], 1e-12))  # Avoid division by zero\n",
    "        else:\n",
    "            R = linalg.inv(SKS + np.diag(lambda_ * weights**(-2)))\n",
    "            levs = np.maximum(0, np.minimum(1, (1/lambda_) * np.maximum(0, k_diag[r_ind_curr] - np.sum((KS @ R) * KS, axis=1))))\n",
    "            levs_sum = np.sum(levs)\n",
    "            if levs_sum == 0 or np.count_nonzero(levs) < s:\n",
    "                samp = np.random.choice(p, size=s, replace=False)\n",
    "            else:\n",
    "                samp = np.random.choice(p, size=s, replace=False, p=levs / levs_sum)\n",
    "        \n",
    "        r_ind = perm[samp]\n",
    "    return r_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrussell_minute_data.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Example of how to use the functions\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m ranks, eigenvalue_diffs, eigenvector_diffs \u001b[38;5;241m=\u001b[39m \u001b[43mtest1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plotting the differences in eigenvalues\u001b[39;00m\n\u001b[1;32m     51\u001b[0m plot_differences(ranks, eigenvalue_diffs, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m Change in Eigenvalues\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDifference in Eigenvalues against SCM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mtest1\u001b[0;34m(X, rank_start, rank_end)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name, method_func \u001b[38;5;129;01min\u001b[39;00m sampling_methods\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     20\u001b[0m     indices \u001b[38;5;241m=\u001b[39m method_func(X, num_landmarks\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m---> 21\u001b[0m     eigenvalues_hat, eigenvectors_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnystrom_pca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Calculate differences\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     eigenvalue_diff \u001b[38;5;241m=\u001b[39m compare_eigenvalues(true_eigenvalues, eigenvalues_hat, r)\n",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m, in \u001b[0;36mnystrom_pca\u001b[0;34m(X, indices, num_landmarks)\u001b[0m\n\u001b[1;32m     65\u001b[0m Z \u001b[38;5;241m=\u001b[39m X[indices_J, :]  \u001b[38;5;66;03m# X_J.shape = (p - num_landmarks, n)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Step 3: Compute Thin SVD of X_I\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m U_Y, D_Y, V_Y_T \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Step 4: Construct W_I and W_J\u001b[39;00m\n\u001b[1;32m     70\u001b[0m W_Y \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(n)) \u001b[38;5;241m*\u001b[39m U_Y \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(D_Y)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/linalg/linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def test1(X, rank_start=2, rank_end=180):\n",
    "    ranks = np.arange(rank_start, rank_end + 1)\n",
    "    sampling_methods = {\n",
    "        'Recursive RLS Sampling': recursive_rls_sample,\n",
    "        'Uniform Sampling': uniform_random_sample,\n",
    "        'Column Norm Sampling': column_norm_sample\n",
    "    }\n",
    "\n",
    "    true_eigenvalues, true_eigenvectors = sample_svd(X)\n",
    "\n",
    "    eigenvalue_diffs = {method_name: [] for method_name in sampling_methods.keys()}\n",
    "    eigenvector_diffs = {method_name: [] for method_name in sampling_methods.keys()}\n",
    "\n",
    "    for r in ranks:\n",
    "        for method_name, method_func in sampling_methods.items():\n",
    "            indices = method_func(X, num_landmarks=r)\n",
    "            eigenvalues_hat, eigenvectors_hat = nystrom_pca(X, indices, r)\n",
    "            \n",
    "            # Calculate differences\n",
    "            eigenvalue_diff = compare_eigenvalues(true_eigenvalues, eigenvalues_hat, r)\n",
    "            eigenvector_diff = compare_eigenvectors(true_eigenvectors, eigenvectors_hat, r)\n",
    "            \n",
    "            # Record differences\n",
    "            eigenvalue_diffs[method_name].append(eigenvalue_diff)\n",
    "            eigenvector_diffs[method_name].append(eigenvector_diff)\n",
    "\n",
    "    return ranks, eigenvalue_diffs, eigenvector_diffs\n",
    "\n",
    "def plot_differences(ranks, diffs, ylabel, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for method_name, diff_values in diffs.items():\n",
    "        rank_percentage = ranks / np.max(ranks) * 100  # Rank as a percentage of max rank\n",
    "        plt.plot(rank_percentage, diff_values, label=method_name)\n",
    "    \n",
    "    plt.xlabel('Rank Percentage (%)')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "X = pd.read_pickle('russell_minute_data.pkl').values\n",
    "# Example of how to use the functions\n",
    "ranks, eigenvalue_diffs, eigenvector_diffs = test1(X)\n",
    "\n",
    "# Plotting the differences in eigenvalues\n",
    "plot_differences(ranks, eigenvalue_diffs, ylabel='% Change in Eigenvalues', title='Difference in Eigenvalues against SCM')\n",
    "\n",
    "# Plotting the differences in eigenvectors\n",
    "plot_differences(ranks, eigenvector_diffs, ylabel='% Change in Eigenvectors', title='Difference in Eigenvectors against SCM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue_diffs = pd.DataFrame(\n",
    "    eigenvalue_diffs, index=ranks\n",
    ")\n",
    "eigenvector_diffs = pd.DataFrame(\n",
    "    eigenvector_diffs, index=ranks\n",
    ")\n",
    "\n",
    "eigenvalue_diffs.to_pickle('eigenvalue_diffs.csv')\n",
    "eigenvector_diffs.to_pickle('eigenvector_diffs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1014, 180)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_pickle('russell_minute_data.pkl').values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019763304569389968\n",
      "1.1874191671590806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalue, eigenvector = sample_svd(X)\n",
    "indices = uniform_random_sample(X, 182)\n",
    "eigenvalues_hat, eigenvectors_hat = nystrom_pca(X, indices, 182)\n",
    "print(compare_eigenvalues(eigenvalue, eigenvalues_hat, 182))\n",
    "print(compare_eigenvectors(eigenvector, eigenvectors_hat, 182))\n",
    "eigenvalue.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
